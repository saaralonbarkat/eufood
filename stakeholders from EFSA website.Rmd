---
title: "Stakeholders from EFSA website"
output:
  html_document:
    code_folding: hide
    always_allow_html: yes
    fig_captions: yes
    highlight: haddock
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
---


```{r set-global-options, echo = FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      message=FALSE,
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      fig.path="Figures/",  # Set the figure options
                      fig.align = "center")
```



```{r}
library(tidyverse)
library(sjPlot)
library(textclean)
```



#EU transparency register

Importing translated database: 
```{r}
eu.trans.food <- sample_01 
```


Counting number of "fields of interest"
```{r}
eu.trans.food <- eu.trans.food %>% 
  mutate(n.fields = str_count(fields,",")) %>% 
  mutate(n.fields.bi = ifelse(n.fields<=10,1,0))

#sjp.frq(eufood$n.fields,type="hist")
```

Counting the appearance of food related words in info
```{r}
foodwords <- "food|drink|agric|pesticid|bevrag|efsa|health|animal|environment|biodiversity|chemical|crop|farm|package|nutrition"

eu.trans.food <- eu.trans.food %>% 
  mutate(info.food = str_detect(info.en.1,foodwords) %>% as.integer(),
        id.trans.new = 1:nrow(eu.trans.food)) %>% 
  rename(id.trans = id,
         organization.name.trans.raw = name,
         organization.section.trans = organization.section,
         organization.subsection.trans = organization.subsection)


eu.trans.food$info.food %>% sjmisc::frq()
```


Cleaning organizations' names in transparency register
```{r}
t1 <- str_split(eu.trans.food$organization.name.trans.raw,"\\(", simplify = TRUE) %>% 
  data.frame() %>% 
  select(organization.name.trans=X1,
         organization.acronym.trans=X2) %>%
  mutate(organization.acronym.trans = str_remove(organization.acronym.trans,"\\)")) %>% 
  mutate(organization.name.trans.clean = organization.name.trans %>% replace_non_ascii() %>%  str_to_lower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|the|of|and",""),
         organization.acronym.trans.clean = organization.acronym.trans %>% replace_non_ascii() %>%  str_to_lower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/| europe| international",""))

eu.trans.food <- eu.trans.food %>% 
  mutate(organization.acronym.trans = t1$organization.acronym.trans,
         organization.acronym.trans.clean = t1$organization.acronym.trans.clean,
         organization.name.trans = t1$organization.name.trans,
         organization.name.trans.clean = t1$organization.name.trans.clean) 


rm(t1)
```

Cleaning presons names.
```{r}
tt1<- eu.trans.food %>%
  mutate(person.head.name.clean = person.head.name %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""),
         person.eu.name.clean = person.eu.name %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W|the|of|and",""))

```


cleaning urls:

```{r}
#removing unneccesary parts of urls for scraping
t1 <- str_split(eu.trans.food$url,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(trans.url.short = X1)

eu.trans.food <- eu.trans.food %>% 
  mutate(trans.url.short = t2$trans.url.short) %>% 
  mutate(trans.url.short.clean = trans.url.short %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(eu.trans.food$url,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.trans.domain.t = str_c(X2,X3)) 

t2 <- str_split(t1$url.trans.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.trans.domain = X1)

eu.trans.food <- eu.trans.food %>% 
  mutate(url.trans.domain = t2$url.trans.domain) %>% 
  mutate(url.trans.domain.clean = url.trans.domain %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))
```


Creating a subset of relevant organizations (with relevant words)
```{r}
eu.trans.food.filter <- filter(eu.trans.food,info.food==1) 

write.csv(eu.trans.food.filter,"sample_food.csv")
```


#Participants from EFSA website

Load data.
```{r}
efsaweb_raw <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/participants efsa meetings.csv") %>% 
  mutate(ORGANIZATION = as.character(ORGANIZATION),
         NAME = as.character(NAME))
  

glimpse(efsaweb_raw)
```



Cleaning organization names and findings unique participants.
```{r}
efsaweb<- efsaweb_raw %>%
  
  drop_na(ORGANIZATION,NAME) %>% 
  
  rename(ids.participant.efsaweb = ID,
         participant.name.efsaweb = NAME,
         organization.name.efsaweb = ORGANIZATION,
         organization.acronym.efsaweb = ACRONYM,
         meeting.title.efsaweb = MEETING,
         meeting.date.efsaweb = DATE,
         meeting.url.efsaweb = URL) %>% 
  
  mutate(participant.name.efsaweb.clean = participant.name.efsaweb %>% str_to_lower() %>% str_replace_all("\\W",""),
         organization.name.efsaweb.clean = organization.name.efsaweb %>% str_to_lower() %>% str_replace_all("\\W|the|of|and",""),
         organization.acronym.efsaweb.clean = organization.acronym.efsaweb %>% str_to_lower() %>% str_replace_all("\\W",""))%>% 
  
  arrange(organization.name.efsaweb.clean, 
          participant.name.efsaweb.clean) %>% 
  
  distinct(participant.name.efsaweb.clean,
           organization.name.efsaweb.clean,.keep_all = T)

efsaweb$participant.name.efsaweb.clean %>% 
  n_distinct()
```

splitting first and last names:
```{r}
efsaweb <- efsaweb %>% 

    mutate(participant.first.name.efsaweb = word(participant.name.efsaweb,1),
         participant.last.name.efsaweb = word(participant.name.efsaweb,-1)) %>% 

    mutate(participant.first.name.efsaweb.clean = tolower(participant.first.name.efsaweb) %>% str_replace_all("\\W",""),
         participant.last.name.efsaweb.clean = tolower(participant.last.name.efsaweb) %>% str_replace_all("\\W",""))
```

Creating acronyms of participant names:
```{r}
t1 <- str_split(efsaweb$participant.name.efsaweb," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>% str_to_lower())) %>% 
  mutate(participant.name.acronym.efsaweb.v1 = str_c(X1,X2,X3,X4,X5)) %>% 
  mutate(participant.name.acronym.efsaweb.v2 = str_c(str_sub(participant.name.acronym.efsaweb.v1,1,1),
                                              str_sub(participant.name.acronym.efsaweb.v1,-1,-1)))


efsaweb <- efsaweb %>% 
  mutate(participant.name.acronym.efsaweb.v1 = t1$participant.name.acronym.efsaweb.v1,
         participant.name.acronym.efsaweb.v2 = t1$participant.name.acronym.efsaweb.v2)

rm(t1)
```

#Registered stakeholders (from EFSA website)
```{r}
#cleaning org names in efsa stakeholders
efsa.stakeholders <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/registered stakeholders.csv") %>%
  
  rename(organization.name.stakeholders = ORGANIZATION,
         acronym.stakeholders = Acronym) %>%
  
  mutate(organization.name.stakeholders.clean = organization.name.stakeholders %>% str_to_lower() %>% str_replace_all("\\W|the|of|and",""),
         organization.acronym.stakeholders.clean = acronym.stakeholders %>% str_to_lower() %>% str_replace_all("\\W","")) %>% 
  mutate(id.efsa.stakeholders = 1:nrow(efsa.stakeholders))

```



#join

##Join registered stakeholders with transparency register
```{r}
t1 <- efsa.stakeholders %>% 
  left_join(eu.trans.food,by=c("organization.acronym.stakeholders.clean"="organization.acronym.trans.clean"))


t1.1 <- t1 %>% 
  filter(is.na(id.trans)==F)

t1.2 <- t1 %>% 
  filter(is.na(id.trans)==T) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("organization.name.stakeholders.clean"="organization.name.trans.clean")) 

efsa.stakeholders.1 <- bind_rows(t1.1,t1.2) 


t1.1 <- efsa.stakeholders.1 %>% 
drop_na(id.trans)

t1.2 <- efsa.stakeholders.1 %>% 
  filter(is.na(id.trans)==T) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("manual.match.id"="id.trans")) 


efsa.stakeholders.1 <- bind_rows(t1.1,t1.2) %>% 
  arrange(id.efsa.stakeholders)%>% 
  mutate(url = ifelse(url %in% NA,url.manual,as.character(url))) %>% 
  mutate(url.clean = tolower(url) %>% str_replace_all("\\W|@|http:|https:","")) 



#rm(t1,t1.1,t1.2)

```


cleaning urls:

```{r}
#removing unneccesary parts of urls for scraping
t1 <- str_split(efsa.stakeholders.1$url,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(trans.url.short = X1)

efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(trans.url.short = t2$trans.url.short) %>% 
  mutate(trans.url.short.clean = trans.url.short %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(efsa.stakeholders.1$url,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.trans.domain.t = str_c(X2,X3)) 

t2 <- str_split(t1$url.trans.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.trans.domain = X1)

efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(url.trans.domain = t2$url.trans.domain) %>% 
  mutate(url.trans.domain.clean = url.trans.domain %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))
```


Organizations from registered stakeholders matched by EU transparency register: 
```{r}
efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(matched.stakeholders.trans = ifelse(id.trans %in% c(NA),0,1))


efsa.stakeholders.1$matched.stakeholders.trans %>% sjmisc::frq()
```

list of unmatched organizations: 
```{r}
efsa.stakeholders.1 %>% 
  filter(matched.stakeholders.trans==0) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders)

```

##Joining stakeholders from meetings with registered stakeholders
```{r}
t1 = efsaweb %>% 
left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.stakeholders.clean"))

t1.1 <- t1 %>%
  drop_na(id.efsa.stakeholders)
  
t1.2.1 <- t1 %>% 
  filter(id.efsa.stakeholders %in% NA) %>% 
  drop_na(organization.acronym.efsaweb.clean) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.acronym.efsaweb.clean"="organization.acronym.stakeholders.clean")) 

t1.2.2 <- t1 %>% 
  filter(id.efsa.stakeholders %in% NA,
         organization.acronym.efsaweb.clean %in% NA) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.stakeholders.clean"))


efsaweb.1 <- bind_rows(t1.1,t1.2.1,t1.2.2) %>% 
    arrange(organization.name.efsaweb.clean, 
            participant.name.efsaweb.clean)


rm(t1,t1.1,t1.2.1,t1.2.2)
```


Stakeholders from meetings matched by registered stakeholder organizations: 
```{r}
efsaweb.1 <- efsaweb.1 %>% 
  mutate(matched.efsaweb.stakeholders = ifelse(id.efsa.stakeholders %in% c(NA),0,1))

efsaweb.1 %>% distinct(organization.name.efsaweb.clean, .keep_all = T) %>%  select(matched.efsaweb.stakeholders) %>% sjmisc::frq()
```


##Joining stakeholders from meetings with transperency register

```{r}
t1 <- efsaweb.1 %>% 
  drop_na(id.trans)

t1.1 <- efsaweb.1 %>% 
  filter(id.trans %in% NA) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("organization.name.efsaweb.clean"="organization.name.trans.clean"))

t1.1.1 <- t1.1 %>%
  drop_na(id.trans)
  
t1.2.1 <- t1.1 %>% 
  filter(id.trans %in% NA) %>% 
  drop_na(organization.acronym.efsaweb.clean) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.acronym.efsaweb.clean"="organization.acronym.trans.clean")) 

t1.2.2 <- t1.1 %>% 
  filter(id.trans %in% NA,
         organization.acronym.efsaweb.clean %in% NA) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.trans.clean"))


efsaweb.2 <- bind_rows(t1,t1.1.1,t1.2.1,t1.2.2) %>% 
    arrange(organization.name.efsaweb.clean, 
            participant.name.efsaweb.clean)
rm(t1,t1.1,t1.1.1,t1.2.1,t1.2.2)

#write_csv(efsaweb_01.2, "C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/participants_short_01.csv")
```

```{r}
efsaweb.2 <- efsaweb.2 %>% 
  mutate(matched.efsaweb.trans = ifelse(id.trans %in% c(NA),0,1))


efsaweb.2 %>% distinct(organization.name.efsaweb.clean, .keep_all = T) %>%  select(matched.efsaweb.trans) %>% sjmisc::frq()

```

list of unmatched organizations: 
```{r}
efsaweb.2 %>% 
  filter(matched.efsaweb.trans==0) %>%
  distinct(organization.name.efsaweb)
```


#URL lists
creating a string of URLs (to feed them to the Python scraper code written by Aaron)

```{r}
#from registered stakeholders
t1.1 <- efsa.stakeholders.1 %>%
  drop_na(url) %>% 
  select(url,
         trans.url.short,
         trans.url.short.clean) %>%
  distinct(trans.url.short,.keep_all = T) %>% 
  mutate(url.new.short.1 = str_c("'","http://",trans.url.short,"',"))


#from participants list
t1.2 <- efsaweb.2 %>% 
  drop_na(url) %>% 
  select(url) %>%
  distinct(url) %>% 
  mutate(url.1 = str_c("'",url,"',"),
         url.clean = tolower(url) %>% str_replace_all("\\W|@|http:|https:","")) 


t1.3 <- eu.trans.food.filter %>% 
  select(trans.url.short,
         trans.url.short.clean) %>%
  distinct(trans.url.short,.keep_all = T) %>% 
  mutate(trans.url.short.1 = str_c("'","http://",trans.url.short,"',")) 



#already crawled:
t2 <- emails %>% 
  distinct(url.escraper.clean)

#Checking whether url exists
t11.1 <- t1.3 %>% anti_join(t2,by=c("trans.url.short.clean"="url.escraper.clean")) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/urlstoscrape_1.csv")


write_csv(t1.2,"C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/urls.csv")


files.df <- files %>% data.frame() %>%  
    mutate(url.escraper=str_replace_all(files.df[,1],"_email_addresses.csv","")) %>% 
  mutate(url.escraper.clean = url.escraper %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:","")) 


files.df %>% 
  distinct(url.escraper.clean)



#Checking whether url exists
t11.1 <- t1.3 %>% anti_join(files.df,by=c("trans.url.short.clean"="url.escraper.clean")) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/urlstoscrape_1.csv")


files.df %>% filter(str_detect(url.escraper,"anamob"))

```


#Emails from escraper
creating a list of emails from email scraper
```{r,warning=FALSE}
# Adding websites to email scraping files

files <- list.files(path = "C:/SAAR/UNIVERSITY/R/eufood/sample building/data/email_scrape_files/")
f <- list()
for (i in 1:length(files)) {
  f[[i]] <- read_csv(str_c("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/email_scrape_files/",files[i])) %>% 
  mutate(url.escraper=str_replace_all(files[i],"_email_addresses.csv",""))}
           


#Binding all files to 1 table 


emails <- bind_rows(f)%>%
  data.frame() %>%  
  select(email.escraper=X1,
         url.email.escraper=X0,
         url.escraper) %>% 
  filter(str_detect(email.escraper,"DSC_")==FALSE,
         str_detect(email.escraper,"png$|jpg$|pdf$|jpeg$")==FALSE) %>% 
  mutate(email.escraper = email.escraper %>% str_to_lower(),
    url.escraper.clean = url.escraper %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))


tt1 <- c("20APng.","aajpG.","pdf","..jpeg")
tt2 <- c("20APng.","aajpG.",NA,"..jpeg")


str_replace(tt1,"^20|\\.$","")
str_detect(tt1,"^[a-z]")
tt1 %>% str_to_lower()
str_c(tt1,str_replace_na(tt2,""))

#removing points at the end of emails + "20" at the begining
emails <- emails %>% 
  mutate(email.escraper = str_replace(email.escraper,"^20|\\.$","")) %>% 

#removing all emails not starting with a letter
    filter(str_detect(email.escraper,"^[a-z]"))

#splitting the local part and the domain part of emails (before and after the @) 
t1=str_split(emails$email.escraper,"@", simplify = TRUE) %>% 
  data.frame() %>% 
  select(local.part=X1,
         domain=X2)

t2 <- str_split(t1$domain,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(domain=X1,
         rest=X2)

emails <- emails %>% 
  mutate(email.escraper.local.part = t1$local.part %>% str_to_lower(),
         email.escraper.domain = t2$domain %>% str_to_lower()) %>% 
  distinct(url.escraper,email.escraper,.keep_all=T) %>% 
  mutate(email.escraper.domain.clean = email.escraper.domain %>% str_replace_all("\\W|@","")) 

rm(files,f,t1,t2)

#Extracting url domains

t1=str_split(emails$url.escraper,"http://|https://", simplify = TRUE) %>% 
  data.frame() 

emails <- emails %>%
mutate(url.escraper.domain = t1$.) %>% 
mutate(url.escraper.domain.clean = url.escraper.domain %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:|www","")) 

```


Finding frequent general local parts
```{r}
emails %>%
  distinct(email.escraper,.keep_all=T) %>%
  group_by(email.escraper.local.part) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq)) %>% 
  filter(freq>5)



emails <- emails%>% 
  mutate(email.general = str_detect(email.escraper.local.part,"info|contact|office|admin|amministrazione|comunication|comunicacion|marketing|international|mail|secretar|segreter|sekretar|presiden|brussels|biuro|post|media|press|media|enquiries|hello|welcome|webmaster|staff|kontakt|enquiries|membership") %>% as.numeric())

emails %>% filter(str_detect(url.escraper,"abbott"))
emails %>% filter(str_detect(email.escraper,"20"))


emails %>%
  select(url.escraper) %>% 
  n_distinct()
  

```


#Matching emails

##participants (efsaweb)

Matching emails with participants names
```{r}
t1.1 <- efsaweb.2 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name = str_detect(email.escraper.local.part,participant.last.name.efsaweb.clean),
         email.first.name = str_detect(email.escraper.local.part,participant.first.name.efsaweb.clean),
         email.name.acronym.v1 = str_detect(email.escraper.local.part,participant.name.acronym.efsaweb.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,participant.name.acronym.efsaweb.v2)) %>% 
  mutate(email.name.match = ifelse(email.last.name==T|
                                     email.first.name==T|
                                     email.name.acronym.v1==T&nchar(email.escraper.local.part)<=4|
                                     email.name.acronym.v2==T&nchar(email.escraper.local.part)<=4,1,0)) %>%
  
  distinct(participant.name.efsaweb.clean,
           organization.name.efsaweb.clean,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==T) %>% 

  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.name.stakeholders,
         acronym.stakeholders,
         ids.participant.efsaweb,
         id.trans,
         organization.name.trans.raw,
         url,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)
  

  
t1.2 <- efsaweb.2 %>% 
  anti_join(t1.1,
            by=c("participant.name.efsaweb"="participant.name.efsaweb")) %>% 
mutate(url.email.escraper = NA,
      email.escraper = NA,
      email.domain.match = NA,
      email.name.match = NA) %>% 
  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.name.stakeholders,
         acronym.stakeholders,
         ids.participant.efsaweb,
         id.trans,
         organization.name.trans.raw,
         url,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)  



efsaweb.emails.personal.2 <- bind_rows(t1.1,t1.2) %>%

  arrange(organization.name.efsaweb,
          participant.name.efsaweb,
          desc(email.name.match)) %>% 
  mutate(url.manual = NA,
         email.person.manual = NA) %>% 
  
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_participants_emails_01.csv")

t1.1$participant.name.efsaweb %>% n_distinct()
efsaweb.emails.personal.2$participant.name.efsaweb %>% n_distinct()
efsaweb.2$participant.name.efsaweb %>% n_distinct()
```

  
```{r}
efsaweb.2$participant.name.efsaweb.clean %>% n_distinct()

efsaweb.emails.personal.1$participant.name.efsaweb.clean %>% n_distinct()
```

adding manual coding
```{r}
email.manual <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_participants_emails_01.MANUALCODING.csv")

email.manual.t <- email.manual %>% 
  select(participant.name.efsaweb,
         url.manual,
         email.person.manual,
         title.person.manual,
         linkedin.manual)


efsaweb.3 <- efsaweb.2 %>% select(-url.manual) %>%  
left_join(email.manual.t,by="participant.name.efsaweb") %>%
  mutate(email.person.manual = email.person.manual %>% str_to_lower(),
         url.manual = url.manual %>% str_to_lower(),
         url.trans = url %>% as.character() %>% str_to_lower()) %>% 
  mutate(url.new = ifelse(url.trans %in% NA,url.manual,url.trans)) %>% 
  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.acronym.efsaweb,
         meeting.url.efsaweb,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         person.head.name,
         person.head.descr,
         person.eu.name,
         person.eu.descr,
         url.trans,
         url.manual,
         url.new,
         email.person.manual,
         title.person.manual,
         linkedin.manual) %>% 
  distinct(participant.name.efsaweb,
           organization.name.efsaweb,
           url.new,
           .keep_all = T)


efsaweb.3 %>% select(email.person.manual) %>% is.na() %>% sjmisc::frq()


#Creating short url.new
t1 <- str_split(efsaweb.3$url.new,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.new.short = X1)

efsaweb.3 <- efsaweb.3 %>% 
  mutate(url.new.short = t2$url.new.short) %>% 
  mutate(url.new.short.clean = url.new.short %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(efsaweb.3$url.new.short,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.new.domain.t = str_c(X1,X2)) 

t2 <- str_split(t1$url.new.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.new.domain = X1)

efsaweb.3 <- efsaweb.3 %>% 
  mutate(url.new.domain = t2$url.new.domain) %>% 
  mutate(url.new.domain.clean = url.new.domain %>% str_to_lower() %>% str_replace_all("\\W|@|http:|https:",""))
```

  

Matching email addresses with patterns of general emails 
  
```{r}  
efsaweb.emails.general.1 <- efsaweb.3 %>% 
  left_join(emails,by=c("url.new.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.new.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.new.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==T & email.domain.match==T,1,0)) %>% 
  distinct(organization.name.efsaweb,email.escraper,.keep_all = T) %>% 
  select(organization.name.efsaweb,
         organization.acronym.efsaweb,
         meeting.url.efsaweb,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         person.head.name,
         person.head.descr,
         person.eu.name,
         person.eu.descr,
         url.trans,
         url.manual,
         url.new,
         email.person.manual,
         title.person.manual,
         linkedin.manual,
         url.email.escraper,
         email.escraper,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.efsaweb,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1 <- efsaweb.emails.general.1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(email.general.str = str_c(email.escraper, collapse = "; "))

t2 <- efsaweb.emails.general.1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(emails.domain.str = str_c(email.escraper, collapse = "; "))

t3 <- efsaweb.emails.general.1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(emails.nondomain.str = str_c(email.escraper, collapse = "; "))

t1 %>% nrow()  



efsaweb.4 <- efsaweb.3 %>% 
  left_join(t1)  %>%
  left_join(t2)  %>%
  left_join(t3)  %>%
  mutate(email.general.manual = NA) %>%
  select(-url.new.short.clean,
         -url.new.domain,
         -url.new.domain.clean) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_emails_01.csv")


efsaweb.4 %>% select(email.person.manual) %>% is.na() %>% sjmisc::frq()

efsaweb.4 %>% 
  filter(!(email.person.manual %in% NA)|
         !(email.general.str %in% NA)) %>% 
  nrow()
```


```{r}
efsaweb.4$organization.name.efsaweb %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(email.general.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(emails.domain.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

```



##efsa stakeholders


tidy data - seperate row for each person
```{r}
efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.1 %>% 
  gather(key=trans.person.type,
             value=trans.person.name,
                c("person.head.name","person.eu.name")) %>% 
  mutate(trans.person.type = recode(trans.person.type,
                                    person.head.name="head",
                                    person.eu.name = "eu person")) %>% 
  mutate(job.descr = if_else(trans.person.type=="head",
                            person.head.descr,
                            person.eu.descr)) %>%
  mutate(trans.person.type.1 = if_else(is.na(trans.person.name==T),"missing", trans.person.type)) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type=trans.person.type.1,
         job.descr,
         organization.type.stakeholders = TYPE,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         organization.acronym.trans,
         organization.name.trans,
         organization.name.trans.clean,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,                
         organization.acronym.trans.clean,
         url.clean,
         matched.stakeholders.trans) %>%
  distinct(organization.name.stakeholders,
         trans.person.name,
         trans.person.type,
         .keep_all = T) %>% 
  arrange(organization.name.stakeholders,
          trans.person.type)

efsa.stakeholders.emails.persons.1$trans.person.name %>%
  n_distinct()
```

splitting first and last names:
```{r}
#cleaning persons names before splitting
efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.emails.persons.1 %>%
  mutate(trans.person.name.1 = str_replace_all(trans.person.name,"Dr. |Dr.|Prof. |Prof.|\\,","")) %>%
    mutate(trans.person.name.1 = 
             str_replace_all(trans.person.name.1,"  "," ")) %>%
  mutate(trans.person.first.name = word(trans.person.name.1,1),
         trans.person.last.name.t = word(trans.person.name.1,-1))

#dealing with cases of two first names (e.g. Alon-Barkat) 
t1.1 <- str_split(efsa.stakeholders.emails.persons.1$trans.person.last.name.t,"-", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(trans.person.last.name.v1 = X1 %>% as.character(),
         trans.person.last.name.v2 = X2 %>% as.character()) %>%
  select(-X1,
         -X2) %>% 
  #mutate(trans.person.last.name.na = nchar(trans.person.last.name.v2)) %>% 
  mutate(trans.person.last.name.v2 = ifelse(nchar(trans.person.last.name.v2)==0,NA,trans.person.last.name.v2))

efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.emails.persons.1 %>% 
  mutate(trans.person.last.name.v1 = t1.1$trans.person.last.name.v1,
         trans.person.last.name.v2 = t1.1$trans.person.last.name.v2) %>% 

#cleaning first and last names
    mutate(trans.person.first.name.clean = trans.person.first.name %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""),
         trans.person.last.name.v1.clean = trans.person.last.name.v1 %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""),
         trans.person.last.name.v2.clean = trans.person.last.name.v2 %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""))
```

Creating acronyms of participant names:
```{r}

t1 <- str_split(efsa.stakeholders.emails.persons.1$trans.person.name.1," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>%  str_to_lower())) %>% 
  mutate(trans.person.name.acronym.v1 = str_c(X1,X2,X3,X4)) %>% 
  mutate(trans.person.name.acronym.v2 = str_c(str_sub(trans.person.name.acronym.v1,1,1),
                                          str_sub(trans.person.name.acronym.v1,-1,-1)))


efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.emails.persons.1 %>% 
  mutate(trans.person.name.acronym.v1 = t1$trans.person.name.acronym.v1 %>% replace_non_ascii() %>% str_replace_all("\\W",""),
         trans.person.name.acronym.v2 = t1$trans.person.name.acronym.v2 %>% replace_non_ascii() %>% str_replace_all("\\W",""))

rm(t1,t2)
```

matching names:
```{r}
t1.1 <- efsa.stakeholders.emails.persons.1 %>%  
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name.v1 = str_detect(email.escraper.local.part,trans.person.last.name.v1.clean),
         email.last.name.v2 = str_detect(email.escraper.local.part,trans.person.last.name.v2.clean),
         email.first.name = str_detect(email.escraper.local.part,trans.person.first.name.clean)) %>%
  mutate(email.name.acronym.v1 = str_detect(email.escraper.local.part,trans.person.name.acronym.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,trans.person.name.acronym.v2)) %>%
  mutate(email.name.acronym = ifelse(nchar(email.escraper.local.part)<=4 &
    (email.name.acronym.v1==T|email.name.acronym.v1==T),1,0)) %>% 
  mutate(email.name.match = ifelse(email.general==0 &
                          str_detect(email.escraper.local.part,email.escraper.domain)==F &
                                     (email.last.name.v1==T|
                                     email.last.name.v2==T|
                                     email.first.name==T|
                                     email.name.acronym==1),1,0)) %>%
  
  distinct(trans.person.name,
           organization.name.stakeholders,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==1) %>%
  
  arrange(organization.name.stakeholders,
         trans.person.type,
         desc(email.last.name.v1),
         desc(email.last.name.v2),
         desc(email.first.name),
         desc(email.domain.match)) %>% 
  
  group_by(trans.person.name) %>% 
  summarise(email.person.str = str_c(email.escraper, collapse = "; "))


efsa.stakeholders.emails.persons.2 <- efsa.stakeholders.emails.persons.1 %>% 
  left_join(t1.1) %>%  

  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type,
         job.descr,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         email.person.str) %>% 
    arrange(organization.name.trans.raw,
          trans.person.type)



t1.1$trans.person.name %>% n_distinct()

efsa.stakeholders.emails.persons.2$trans.person.name %>% n_distinct()

efsa.stakeholders.emails.persons.2 %>% 
  distinct(trans.person.name,.keep_all = T) %>% 
  select(trans.person.name,email.person.str) %>% 
  drop_na()

```


Adding general email addresses: 
 
```{r}  
t1 <- efsa.stakeholders.emails.persons.1 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.trans.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.trans.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==1 & email.domain.match==1,1,0)) %>% 
  distinct(organization.name.stakeholders,email.escraper,.keep_all = T) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type,
         job.descr,
         organization.type.stakeholders,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.stakeholders,
          trans.person.type,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1.1 <- t1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(email.general.str = str_c(email.escraper, collapse = "; "))

t1.2 <- t1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(emails.domain.str = str_c(email.escraper, collapse = "; "))

t1.3 <- t1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(emails.nondomain.str = str_c(email.escraper, collapse = "; "))
  

efsa.stakeholders.emails.persons.2 <- efsa.stakeholders.emails.persons.2 %>% 
  left_join(t1.1)  %>%
  left_join(t1.2)  %>%
  left_join(t1.3)  %>%
  mutate(email.general.manual = NA) %>%
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders.emails_01.csv")

efsa.stakeholders.emails.persons.2$organization.name.stakeholders %>% n_distinct()


efsa.stakeholders.emails.persons.2 %>% select(organization.name.stakeholders,email.general.str) %>%
  distinct(organization.name.stakeholders,.keep_all = T) %>% 
  drop_na()

```

Joining with participants:
```{r}
t1 <- efsaweb.4 %>% 
  select(participant.name.efsaweb,
         organization.name.efsaweb,
         id.efsa.stakeholders,
         email.person.manual,
         email.general.manual) %>% 
  group_by(id.efsa.stakeholders) %>% 
  summarise(participant.name.efsaweb.str = str_c(participant.name.efsaweb,collapse = "; "),
    email.person.manual.efsaweb.str = str_c(email.person.manual,collapse = "; "),
             email.general.manual.efsaweb.str = str_c(email.general.manual,collapse = "; "))

efsa.stakeholders.emails.persons.3 <- efsa.stakeholders.emails.persons.2 %>% 
  left_join(t1) %>%
  mutate(efsaweb.participant.match = NA) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders.emails_MANUAL_01.csv")
```



##transparency register

tidy data - seperate row for each person
```{r}
eu.trans.food.filter.2 <- eu.trans.food.filter %>% 
  gather(key=trans.person.type,
             value=trans.person.name,
                c("person.head.name","person.eu.name")) %>% 
  mutate(trans.person.type = recode(trans.person.type,
                                    person.head.name="head",
                                    person.eu.name = "eu person")) %>% 
  mutate(job.descr = if_else(trans.person.type=="head",
                            person.head.descr,
                            person.eu.descr)) %>%
  mutate(trans.person.type.1 = if_else(is.na(trans.person.name==T),"missing", trans.person.type)) %>% 
  
  select(trans.person.name,
         trans.person.type=trans.person.type.1,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         organization.acronym.trans,
         organization.name.trans,
         organization.name.trans.clean,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,                
         organization.acronym.trans.clean) %>%
  
distinct(organization.name.trans.raw,
         trans.person.name,
         trans.person.type,
         .keep_all = T) %>% 
  arrange(organization.name.trans.raw,
          trans.person.type)


t1 <- eu.trans.food.filter.2 %>% 
  group_by(trans.person.name,
           organization.name.trans.raw) %>% 
  summarise(trans.person.type.str = str_c(trans.person.type, collapse = "; "))

eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>%
  distinct(trans.person.name, organization.name.trans.raw,
           .keep_all = T) %>% 
  left_join(t1) %>% 
  mutate(trans.person.type = trans.person.type.str)


eu.trans.food.filter.2$trans.person.name %>%
  n_distinct()
```

splitting first and last names:
```{r}
#cleaning persons names before splitting
eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>%
  mutate(trans.person.name.1 = str_replace_all(trans.person.name,"Dr. |Dr.|Prof. |Prof.|\\,","")) %>%
    mutate(trans.person.name.1 = 
             str_replace_all(trans.person.name.1,"  "," ")) %>%
  mutate(trans.person.first.name = word(trans.person.name.1,1),
         trans.person.last.name.t = word(trans.person.name.1,-1))

#dealing with cases of two first names (e.g. Alon-Barkat) 
t1.1 <- str_split(eu.trans.food.filter.2$trans.person.last.name.t,"-", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(trans.person.last.name.v1 = X1 %>% as.character(),
         trans.person.last.name.v2 = X2 %>% as.character()) %>%
  select(-X1,
         -X2) %>% 
  #mutate(trans.person.last.name.na = nchar(trans.person.last.name.v2)) %>% 
  mutate(trans.person.last.name.v2 = ifelse(nchar(trans.person.last.name.v2)==0,NA,trans.person.last.name.v2))

eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>% 
  mutate(trans.person.last.name.v1 = t1.1$trans.person.last.name.v1,
         trans.person.last.name.v2 = t1.1$trans.person.last.name.v2) %>% 

#cleaning first and last names
    mutate(trans.person.first.name.clean = trans.person.first.name %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""),
         trans.person.last.name.v1.clean = trans.person.last.name.v1 %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""),
         trans.person.last.name.v2.clean = trans.person.last.name.v2 %>% replace_non_ascii() %>% str_to_lower() %>% str_replace_all("\\W",""))




eu.trans.food.filter.2 %>%
  distinct(trans.person.name,.keep_all=T) %>%
  group_by(trans.person.first.name) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq)) 

eu.trans.food.filter.2 %>%
  distinct(trans.person.name,.keep_all=T) %>%
  group_by(trans.person.last.name.v1) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq)) 

eu.trans.food.filter.2 %>%
  distinct(trans.person.name,.keep_all=T) %>%
  group_by(trans.person.last.name.v2) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq))

```

Creating acronyms of participant names:
```{r}

t1 <- str_split(eu.trans.food.filter.2$trans.person.name.1," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>%  str_to_lower())) %>% 
  mutate(trans.person.name.acronym.v1 = str_c(X1,X2,X3,X4,X5)) %>% 
  mutate(trans.person.name.acronym.v2 = str_c(str_sub(trans.person.name.acronym.v1,1,1),
                                          str_sub(trans.person.name.acronym.v1,-1,-1)))


eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>% 
  mutate(trans.person.name.acronym.v1 = t1$trans.person.name.acronym.v1 %>% replace_non_ascii() %>% str_replace_all("\\W",""),
         trans.person.name.acronym.v2 = t1$trans.person.name.acronym.v2 %>% replace_non_ascii() %>% str_replace_all("\\W",""))

rm(t1)

eu.trans.food.filter.2 %>%
  #distinct(trans.person.first.name,.keep_all=T) %>%
  group_by(trans.person.name.acronym.v1,
           trans.person.name.acronym.v2) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq))
```

matching names:
```{r}
t1.1 <- eu.trans.food.filter.2 %>%  
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name.v1 = str_detect(email.escraper.local.part,trans.person.last.name.v1.clean),
         email.last.name.v2 = str_detect(email.escraper.local.part,trans.person.last.name.v2.clean),
         email.first.name = str_detect(email.escraper.local.part,trans.person.first.name.clean)) %>%
  mutate(email.name.acronym.v1 = str_detect(email.escraper.local.part,trans.person.name.acronym.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,trans.person.name.acronym.v2)) %>%
  mutate(email.name.acronym = ifelse(nchar(email.escraper.local.part)<=4 &
    (email.name.acronym.v1==T|email.name.acronym.v1==T),1,0)) %>% 
  mutate(email.name.match = ifelse(email.general==0 &
                          str_detect(email.escraper.local.part,email.escraper.domain)==F &
                                     (email.last.name.v1==T|
                                     email.last.name.v2==T|
                                     email.first.name==T|
                                     email.name.acronym==1),1,0)) %>%
  
  distinct(trans.person.name,
           organization.name.trans.raw,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==1) %>%
  
  arrange(trans.person.name,
         trans.person.type,
         desc(email.last.name.v1),
         desc(email.last.name.v2),
         desc(email.first.name),
         desc(email.domain.match)) %>% 
  
  group_by(trans.person.name) %>% 
  summarise(email.person.str = str_c(email.escraper, collapse = "; "))
  

eu.trans.food.filter.3 <- eu.trans.food.filter.2 %>% 
  left_join(t1.1) %>%  

  select(trans.person.name,
         trans.person.type,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         email.person.str) %>% 
    arrange(organization.name.trans.raw,
          trans.person.type)

  #write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders_01.csv")

t1.1$trans.person.name %>% n_distinct()
eu.trans.food.filter.3 %>% 
  distinct(trans.person.name,.keep_all = T) %>% 
  select(trans.person.name,email.person.str) %>% 
  drop_na()

```


Adding general email addresses: 
 
```{r}  
t1 <- eu.trans.food.filter.2 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.trans.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.trans.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==1 & email.domain.match==1,1,0)) %>% 
  distinct(organization.name.trans.raw,email.escraper,.keep_all = T) %>% 
  select(trans.person.name,
         trans.person.type,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         organization.section.trans,
         organization.subsection.trans,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.trans.raw,
          trans.person.type,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1.1 <- t1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(email.general.str = str_c(email.escraper, collapse = "; "))

t1.2 <- t1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(emails.domain.str = str_c(email.escraper, collapse = "; "))

t1.3 <- t1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(emails.nondomain.str = str_c(email.escraper, collapse = "; "))
  

eu.trans.food.filter.3 <- eu.trans.food.filter.3 %>% 
  left_join(t1.1)  %>%
  left_join(t1.2)  %>%
  left_join(t1.3)  %>%
  mutate(email.general.manual = NA) %>%
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.trans.emails_01.csv")

eu.trans.food.filter.3$organization.name.trans.raw %>% n_distinct()


eu.trans.food.filter.3 %>% 
  select(organization.name.trans.raw,email.general.str) %>%
  distinct(organization.name.trans.raw,.keep_all = T) %>% 
  drop_na()

```


```{r}
eu.trans.food.filter.3 %>% nrow()

eu.trans.food.filter.3$organization.name.trans.raw %>% 
  n_distinct()

eu.trans.food.filter.3 %>%
  drop_na(email.person.str) %>% 
  select(trans.person.name) %>% 
  n_distinct()

eu.trans.food.filter.3 %>%
  drop_na(emails.domain.str) %>% 
  select(trans.person.name) %>% 
  n_distinct()

eu.trans.food.filter.3$general.email.bi %>% table()

```

calculating differences accross organization types
```{r}
eu.trans.food.filter.3 <- eu.trans.food.filter.3 %>% 
  mutate(email.person.bi = ifelse(email.person.str %in% NA,0,1),
         general.email.bi = ifelse(email.general.str %in% NA,0,1))

#personal emails
eu.trans.food.filter.3 %>%
  group_by(organization.section.trans) %>% 
  summarise(n.orgs = n_distinct(organization.name.trans.raw),
            n.persons = n_distinct(trans.person.name),
            n.persons.emails = sum(email.person.bi),
            n.general.emails = sum(general.email.bi)) %>% 
  mutate(percent.persons.emails = round((n.persons.emails/n.persons),2),
         percent.general.emails = round((n.general.emails/n.persons),2))

eu.trans.food.filter.3 %>%
  group_by(organization.section.trans,
           organization.subsection.trans) %>% 
  summarise(n.orgs = n_distinct(organization.name.trans.raw),
            n.persons = n_distinct(trans.person.name),
            n.persons.emails = sum(email.person.bi),
            n.general.emails = sum(general.email.bi)) %>% 
  mutate(percent.persons.emails = round((n.persons.emails/n.persons),2),
         percent.general.emails = round((n.general.emails/n.persons),2))

           
```


#Power group

efsaweb (participants from meetings)
```{r}
efsaweb.4 %>% names()

t1 <- efsaweb.4 %>% 
  select(person.name = participant.name.efsaweb,
         person.descr = title.person.manual,
         organization.name = organization.name.efsaweb,
         organization.name.trans.raw,
         id.efsa.stakeholders,
         id.trans,
         url.trans,
         url.manual,
         email.person = email.person.manual,
         email.general.str,
         linkedin.manual) %>% 
  mutate(organization.url = ifelse(url.trans %in% NA,url.manual,url.trans),
         source = "participant",
         trans.person.type = NA) %>% 
  select(-url.trans,
         -url.manual)

t1 %>% names()
```

registered stakeholders
```{r}
efsa.stakeholders.emails.manual <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_stakeholders_emails_MANUAL_coded.csv")

efsa.stakeholders.emails.manual %>% names()

t2 <- efsa.stakeholders.emails.manual %>% 
  select(trans.person.name,
         person.name.maunal,
         trans.person.type,
         job.descr,
         person.title.manual,
         organization.name = organization.name.stakeholders,
         organization.name.trans.raw,
         id.efsa.stakeholders,
         id.trans,
         organization.url = url,
         email.person = email.person.manual.1,
         email.general.str,
         email.general.manual.12,
         efsaweb.participant.match) %>% 
  mutate(person.name = ifelse(trans.person.name %in% NA,person.name.maunal,trans.person.name),
         person.descr = ifelse(job.descr %in% NA,person.title.manual,job.descr),
         email.general.str = ifelse(email.general.str %in% NA,email.general.manual.12,email.general.str),
         linkedin.manual = NA) %>%
  filter(efsaweb.participant.match==0) %>% 
  mutate(source = "registered stakeholders") 
  
t2.1 <- t2 %>% 
  group_by(person.name,
           organization.name) %>% 
  summarise(trans.person.type.str = str_c(trans.person.type, collapse = "; ") %>% na_if("missing"))

t2 <- t2 %>%
  distinct(person.name, organization.name,
           .keep_all = T) %>% 
  left_join(t2.1) %>% 
  mutate(trans.person.type = trans.person.type.str) %>% 
  .[,t1 %>% names] 
```

combining
```{r}
power.group.emails.1 <- rbind(t1,t2) 

t1 <- power.group.emails.1 %>% 
  distinct(organization.url,
           email.general.str) %>% 
  rename(email.general.str.1 = email.general.str) %>% 
  group_by(organization.url) %>% 
  summarise(email.general.str.2 = str_c(email.general.str.1,collapse = "; "))

power.group.emails.2 <- power.group.emails.1 %>% 
  left_join(t1) %>% 
  mutate(email.general.str = ifelse(email.general.str==email.general.str.2,email.general.str,email.general.str.2)) %>% 
  select(-email.general.str.2)%>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/power.group.emails.1.csv")
```


manually adding a couple of general emails:
```{r}
t1 <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/power.group.emails.manualcoding.csv")

power.group.emails.3 <- power.group.emails.2 %>% 
  mutate(email.general.str = ifelse(email.general.str %in% NA,t1$email.general.manual,email.general.str)) %>%
  distinct(person.name,
           organization.name,
           .keep_all = T) %>% 
    write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/power.group.emails.3.csv")

#number personal emails found: 
t1 = power.group.emails.3$email.person %>% n_distinct()
t1
#% found personal emails:
t2 = t1/(power.group.emails.3 %>% nrow())
t2 %>% round(3)
#number personal/general emails found: 
power.group.emails.3 %>% 
  mutate(mail.bi = ifelse(email.person %in% NA &
                            email.general.str %in% NA,0,1)) %>% 
  select(mail.bi) %>% 
  table()

```


```{r}
t1 <- power.group.emails.3 %>% 
  distinct(email.person) %>% 
  rename(email.person.str=email.person)

t2 <- eu.trans.food.filter.3 %>% 
  distinct(email.person.str)

t3 <- rbind(t1,t2)
nrow(t3)-nrow(t1)
```


#END