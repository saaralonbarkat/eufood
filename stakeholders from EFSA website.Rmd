---
title: "Stakeholders from EFSA website"
output:
  html_document:
    code_folding: hide
    always_allow_html: yes
    fig_captions: yes
    highlight: haddock
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
---


```{r set-global-options, echo = FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      message=FALSE,
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      fig.path="Figures/",  # Set the figure options
                      fig.align = "center")
```



```{r}
library(tidyverse)
library(sjPlot)
```



#EU transparency register

Importing translated database: 
```{r}
eu.trans.food <- sample_01 
```


Counting number of "fields of interest"
```{r}
eu.trans.food <- eu.trans.food %>% 
  mutate(n.fields = str_count(fields,",")) %>% 
  mutate(n.fields.bi = ifelse(n.fields<=10,1,0))

#sjp.frq(eufood$n.fields,type="hist")
```

Counting the appearance of food related words in info
```{r}
foodwords <- "food|drink|agric|pesticid|bevrag|efsa|health|animal|environment|biodiversity|chemical|crop|farm|package|nutrition"

eu.trans.food <- eu.trans.food %>% 
  mutate(info.food = str_detect(info.en.1,foodwords) %>% as.integer(),
        id.trans.new = 1:nrow(eu.trans.food)) %>% 
  rename(id.trans = id,
         organization.name.trans.raw = name)


eu.trans.food$info.food %>% sjmisc::frq()
```


Cleaning organizations' names in transparency register
```{r}
t1 <- str_split(eu.trans.food$organization.name.trans.raw,"\\(", simplify = TRUE) %>% 
  data.frame() %>% 
  select(organization.name.trans=X1,
         organization.acronym.trans=X2) %>%
  mutate(organization.acronym.trans = str_remove(organization.acronym.trans,"\\)")) %>% 
  mutate(organization.name.trans.clean = organization.name.trans %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|the|of|and",""),
         organization.acronym.trans.clean = organization.acronym.trans %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/| europe| international",""))

eu.trans.food <- eu.trans.food %>% 
  mutate(organization.acronym.trans = t1$organization.acronym.trans,
         organization.acronym.trans.clean = t1$organization.acronym.trans.clean,
         organization.name.trans = t1$organization.name.trans,
         organization.name.trans.clean = t1$organization.name.trans.clean) 


rm(t1)
```

Cleaning presons names.
```{r}
tt1<- eu.trans.food %>%
  mutate(person.head.name.clean = person.head.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""),
         person.eu.name.clean = person.eu.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|the|of|and",""))

```


cleaning urls:

```{r}
#removing unneccesary parts of urls for scraping
t1 <- str_split(eu.trans.food$url,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(trans.url.short = X1)

eu.trans.food <- eu.trans.food %>% 
  mutate(trans.url.short = t2$trans.url.short) %>% 
  mutate(trans.url.short.clean = trans.url.short %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(eu.trans.food$url,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.trans.domain.t = paste0(X2,X3)) 

t2 <- str_split(t1$url.trans.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.trans.domain = X1)

eu.trans.food <- eu.trans.food %>% 
  mutate(url.trans.domain = t2$url.trans.domain) %>% 
  mutate(url.trans.domain.clean = url.trans.domain %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))
```


Creating a subset of relevant organizations (with relevant words)
```{r}
eu.trans.food.filter <- filter(eu.trans.food,info.food==1) 

write.csv(eu.trans.food.filter,"sample_food.csv")
```


#Participants from EFSA website

Load data.
```{r}
efsaweb_raw <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/participants efsa meetings.csv") %>% 
  mutate(ORGANIZATION = as.character(ORGANIZATION),
         NAME = as.character(NAME))
  

glimpse(efsaweb_raw)
```



Cleaning organization names and findings unique participants.
```{r}
efsaweb<- efsaweb_raw %>%
  
  drop_na(ORGANIZATION,NAME) %>% 
  
  rename(ids.participant.efsaweb = ID,
         participant.name.efsaweb = NAME,
         organization.name.efsaweb = ORGANIZATION,
         organization.acronym.efsaweb = ACRONYM,
         meeting.title.efsaweb = MEETING,
         meeting.date.efsaweb = DATE,
         meeting.url.efsaweb = URL) %>% 
  
  mutate(participant.name.efsaweb.clean = participant.name.efsaweb %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""),
         organization.name.efsaweb.clean = organization.name.efsaweb %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|the|of|and",""),
         organization.acronym.efsaweb.clean = organization.acronym.efsaweb %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""))%>% 
  
  arrange(organization.name.efsaweb.clean, 
          participant.name.efsaweb.clean) %>% 
  
  distinct(participant.name.efsaweb.clean,
           organization.name.efsaweb.clean,.keep_all = T)

efsaweb$participant.name.efsaweb.clean %>% 
  n_distinct()
```

splitting first and last names:
```{r}
efsaweb <- efsaweb %>% 

    mutate(participant.first.name.efsaweb = word(participant.name.efsaweb,1),
         participant.last.name.efsaweb = word(participant.name.efsaweb,-1)) %>% 

    mutate(participant.first.name.efsaweb.clean = tolower(participant.first.name.efsaweb) %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""),
         participant.last.name.efsaweb.clean = tolower(participant.last.name.efsaweb) %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""))
```

Creating acronyms of participant names:
```{r}
t1 <- str_split(efsaweb$participant.name.efsaweb," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>% tolower())) %>% 
  mutate(participant.name.acronym.efsaweb.v1 = paste0(X1,X2,X3,X4,X5)) %>% 
  mutate(participant.name.acronym.efsaweb.v2 = paste0(str_sub(participant.name.acronym.efsaweb.v1,1,1),
                                              str_sub(participant.name.acronym.efsaweb.v1,-1,-1)))


efsaweb <- efsaweb %>% 
  mutate(participant.name.acronym.efsaweb.v1 = t1$participant.name.acronym.efsaweb.v1,
         participant.name.acronym.efsaweb.v2 = t1$participant.name.acronym.efsaweb.v2)

rm(t1)
```

#Registered stakeholders (from EFSA website)
```{r}
#cleaning org names in efsa stakeholders
efsa.stakeholders <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/registered stakeholders.csv") %>%
  
  rename(organization.name.stakeholders = ORGANIZATION,
         acronym.stakeholders = Acronym) %>%
  
  mutate(organization.name.stakeholders.clean = organization.name.stakeholders %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|the|of|and",""),
         organization.acronym.stakeholders.clean = acronym.stakeholders %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’","")) %>% 
  mutate(id.efsa.stakeholders = 1:nrow(efsa.stakeholders))

```



#join

##Join registered stakeholders with transparency register
```{r}
t1 <- efsa.stakeholders %>% 
  left_join(eu.trans.food,by=c("organization.acronym.stakeholders.clean"="organization.acronym.trans.clean"))


t1.1 <- t1 %>% 
  filter(is.na(id.trans)==F)

t1.2 <- t1 %>% 
  filter(is.na(id.trans)==T) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("organization.name.stakeholders.clean"="organization.name.trans.clean")) 

efsa.stakeholders.1 <- bind_rows(t1.1,t1.2) 


t1.1 <- efsa.stakeholders.1 %>% 
drop_na(id.trans)

t1.2 <- efsa.stakeholders.1 %>% 
  filter(is.na(id.trans)==T) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("manual.match.id"="id.trans")) 


efsa.stakeholders.1 <- bind_rows(t1.1,t1.2) %>% 
  arrange(id.efsa.stakeholders)%>% 
  mutate(url = ifelse(url %in% NA,url.manual,as.character(url))) %>% 
  mutate(url.clean = tolower(url) %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:","")) %>% 
  select(-info.en,
         -acronym.1,
         -orgname.1,
         -n.fields.bi,
         -manual.match.id)


#rm(t1,t1.1,t1.2)

```


cleaning urls:

```{r}
#removing unneccesary parts of urls for scraping
t1 <- str_split(efsa.stakeholders.1$url,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(trans.url.short = X1)

efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(trans.url.short = t2$trans.url.short) %>% 
  mutate(trans.url.short.clean = trans.url.short %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(efsa.stakeholders.1$url,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.trans.domain.t = paste0(X2,X3)) 

t2 <- str_split(t1$url.trans.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.trans.domain = X1)

efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(url.trans.domain = t2$url.trans.domain) %>% 
  mutate(url.trans.domain.clean = url.trans.domain %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))
```


Organizations from registered stakeholders matched by EU transparency register: 
```{r}
efsa.stakeholders.1 <- efsa.stakeholders.1 %>% 
  mutate(matched.stakeholders.trans = ifelse(id.trans %in% c(NA),0,1))


efsa.stakeholders.1$matched.stakeholders.trans %>% sjmisc::frq()
```

list of unmatched organizations: 
```{r}
efsa.stakeholders.1 %>% 
  filter(matched.stakeholders.trans==0) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders)

```

##Joining stakeholders from meetings with registered stakeholders
```{r}
t1 = efsaweb %>% 
left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.stakeholders.clean"))

t1.1 <- t1 %>%
  drop_na(id.efsa.stakeholders)
  
t1.2.1 <- t1 %>% 
  filter(id.efsa.stakeholders %in% NA) %>% 
  drop_na(organization.acronym.efsaweb.clean) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.acronym.efsaweb.clean"="organization.acronym.stakeholders.clean")) 

t1.2.2 <- t1 %>% 
  filter(id.efsa.stakeholders %in% NA,
         organization.acronym.efsaweb.clean %in% NA) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.stakeholders.clean"))


efsaweb.1 <- bind_rows(t1.1,t1.2.1,t1.2.2) %>% 
    arrange(organization.name.efsaweb.clean, 
            participant.name.efsaweb.clean)


rm(t1,t1.1,t1.2.1,t1.2.2)
```


Stakeholders from meetings matched by registered stakeholder organizations: 
```{r}
efsaweb.1 <- efsaweb.1 %>% 
  mutate(matched.efsaweb.stakeholders = ifelse(id.efsa.stakeholders %in% c(NA),0,1))

efsaweb.1 %>% distinct(organization.name.efsaweb.clean, .keep_all = T) %>%  select(matched.efsaweb.stakeholders) %>% sjmisc::frq()
```


##Joining stakeholders from meetings with transperency register

```{r}
t1 <- efsaweb.1 %>% 
  drop_na(id.trans)

t1.1 <- efsaweb.1 %>% 
  filter(id.trans %in% NA) %>% 
  select(1:"id.efsa.stakeholders") %>% 
  left_join(eu.trans.food,by=c("organization.name.efsaweb.clean"="organization.name.trans.clean"))

t1.1.1 <- t1.1 %>%
  drop_na(id.trans)
  
t1.2.1 <- t1.1 %>% 
  filter(id.trans %in% NA) %>% 
  drop_na(organization.acronym.efsaweb.clean) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.acronym.efsaweb.clean"="organization.acronym.trans.clean")) 

t1.2.2 <- t1.1 %>% 
  filter(id.trans %in% NA,
         organization.acronym.efsaweb.clean %in% NA) %>% 
  select(1:"organization.acronym.efsaweb.clean") %>% 
  left_join(efsa.stakeholders.1,by=c("organization.name.efsaweb.clean"="organization.name.trans.clean"))


efsaweb.2 <- bind_rows(t1,t1.1.1,t1.2.1,t1.2.2) %>% 
    arrange(organization.name.efsaweb.clean, 
            participant.name.efsaweb.clean)
rm(t1,t1.1,t1.1.1,t1.2.1,t1.2.2)

#write_csv(efsaweb_01.2, "C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/participants_short_01.csv")
```

```{r}
efsaweb.2 <- efsaweb.2 %>% 
  mutate(matched.efsaweb.trans = ifelse(id.trans %in% c(NA),0,1))


efsaweb.2 %>% distinct(organization.name.efsaweb.clean, .keep_all = T) %>%  select(matched.efsaweb.trans) %>% sjmisc::frq()

```

list of unmatched organizations: 
```{r}
efsaweb.2 %>% 
  filter(matched.efsaweb.trans==0) %>%
  distinct(organization.name.efsaweb)
```


#URL lists
creating a string of URLs (to feed them to the Python scraper code written by Aaron)

```{r}
#from registered stakeholders
t1.1 <- efsa.stakeholders.1 %>%
  drop_na(url) %>% 
  select(url,
         trans.url.short,
         trans.url.short.clean) %>%
  distinct(trans.url.short,.keep_all = T) %>% 
  mutate(url.new.short.1 = paste0("'","http://",trans.url.short,"',"))


#from participants list
t1.2 <- efsaweb.2 %>% 
  drop_na(url) %>% 
  select(url) %>%
  distinct(url) %>% 
  mutate(url.1 = paste0("'",url,"',"),
         url.clean = tolower(url) %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:","")) 


t1.3 <- eu.trans.food.filter %>% 
  select(trans.url.short,
         trans.url.short.clean) %>%
  distinct(trans.url.short,.keep_all = T) %>% 
  mutate(trans.url.short.1 = paste0("'","http://",trans.url.short,"',")) 



#already crawled:
t2 <- emails %>% 
  distinct(url.escraper.clean)

#Checking whether url exists
t11.1 <- t1.3 %>% anti_join(t2,by=c("trans.url.short.clean"="url.escraper.clean")) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/urlstoscrape_1.csv")


write_csv(t1.2,"C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/urls.csv")

```


#Emails from escraper
creating a list of emails from email scraper
```{r,warning=FALSE}
# Adding websites to email scraping files

files <- list.files(path = "C:/SAAR/UNIVERSITY/R/eufood/sample building/data/email_scrape_files/")
f <- list()
for (i in 1:length(files)) {
  f[[i]] <- read_csv(paste0("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/email_scrape_files/",files[i])) %>% 
  mutate(url.escraper=str_split(files[i],"_email_addresses.csv")[[1]][1])
  }

#Binding all files to 1 table 

emails <- bind_rows(f)%>%
  data.frame() %>%  
  select(email.escraper=X1,
         url.email.escraper=X0,
         url.escraper) %>% 
  filter(str_detect(email.escraper,"DSC_")==FALSE,
         str_sub(email.escraper,-3,-1)!="png") %>% 
  mutate(email.escraper = email.escraper %>% tolower(),
    url.escraper.clean = url.escraper %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))

#removing points at the end of emails
emails <- emails %>% 
  mutate(email.escraper = ifelse(substr(email.escraper,nchar(email.escraper),nchar(email.escraper))==".",str_sub(email.escraper, 1, end=-2),email.escraper))

#splitting the local part and the domain part of emails (before and after the @) 
t1=str_split(emails$email.escraper,"@", simplify = TRUE) %>% 
  data.frame() %>% 
  select(local.part=X1,
         domain=X2)

t2 <- str_split(t1$domain,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(domain=X1,
         rest=X2)

emails <- emails %>% 
  mutate(email.escraper.local.part = t1$local.part %>% tolower(),
         email.escraper.domain = t2$domain %>% tolower()) %>% 
  distinct(url.escraper,email.escraper,.keep_all=T) %>% 
  mutate(email.escraper.domain.clean = email.escraper.domain %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@","")) 

rm(files,f,t1,t2)

#Extracting url domains

t1=str_split(emails$url.escraper,"http://|https://", simplify = TRUE) %>% 
  data.frame() 

emails <- emails %>%
mutate(url.escraper.domain = t1$.) %>% 
mutate(url.escraper.domain.clean = url.escraper.domain %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:|www","")) 

```


Finding frequent general local parts
```{r}
emails %>%
  distinct(email.escraper,.keep_all=T) %>%
  group_by(email.escraper.local.part) %>% 
  summarise(freq=n()) %>% 
  arrange(desc(freq)) %>% 
  filter(freq>5)



emails <- emails%>% 
  mutate(email.general = str_detect(email.escraper.local.part,"info|contact|office|admin|international|mail|secretariat|secretary|post|media|press|media|enquiries|hello|webmaster|staff|kontakt|enquiries|membership") %>% as.numeric())

emails %>% filter(str_detect(url.escraper,"mercadona"))
```


#Matching emails

##participants (efsaweb)

Matching emails with participants names
```{r}
t1.1 <- efsaweb.2 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name = str_detect(email.escraper.local.part,participant.last.name.efsaweb.clean),
         email.first.name = str_detect(email.escraper.local.part,participant.first.name.efsaweb.clean),
         email.name.acronym.v1 = str_detect(email.escraper.local.part,participant.name.acronym.efsaweb.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,participant.name.acronym.efsaweb.v2)) %>% 
  mutate(email.name.match = ifelse(email.last.name==T|
                                     email.first.name==T|
                                     email.name.acronym.v1==T&nchar(email.escraper.local.part)<=4|
                                     email.name.acronym.v2==T&nchar(email.escraper.local.part)<=4,1,0)) %>%
  
  distinct(participant.name.efsaweb.clean,
           organization.name.efsaweb.clean,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==T) %>% 

  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.name.stakeholders,
         acronym.stakeholders,
         ids.participant.efsaweb,
         id.trans,
         organization.name.trans.raw,
         url,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)
  

  
t1.2 <- efsaweb.2 %>% 
  anti_join(t1.1,
            by=c("participant.name.efsaweb"="participant.name.efsaweb")) %>% 
mutate(url.email.escraper = NA,
      email.escraper = NA,
      email.domain.match = NA,
      email.name.match = NA) %>% 
  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.name.stakeholders,
         acronym.stakeholders,
         ids.participant.efsaweb,
         id.trans,
         organization.name.trans.raw,
         url,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)  



efsaweb.emails.personal.2 <- bind_rows(t1.1,t1.2) %>%

  arrange(organization.name.efsaweb,
          participant.name.efsaweb,
          desc(email.name.match)) %>% 
  mutate(url.manual = NA,
         email.person.manual = NA) %>% 
  
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_participants_emails_01.csv")

t1.1$participant.name.efsaweb %>% n_distinct()
efsaweb.emails.personal.2$participant.name.efsaweb %>% n_distinct()
efsaweb.2$participant.name.efsaweb %>% n_distinct()
```

  
```{r}
efsaweb.2$participant.name.efsaweb.clean %>% n_distinct()

efsaweb.emails.personal.1$participant.name.efsaweb.clean %>% n_distinct()
```

adding manual coding
```{r}
email.manual <- read_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_participants_emails_01.MANUALCODING.csv")

email.manual.t <- email.manual %>% 
  select(participant.name.efsaweb,
         url.manual,
         email.person.manual,
         title.person.manual,
         linkedin.manual)


efsaweb.3 <- efsaweb.2 %>% select(-url.manual) %>%  
left_join(email.manual.t,by="participant.name.efsaweb") %>%
  mutate(email.person.manual = email.person.manual %>% tolower(),
         url.manual = url.manual %>% tolower(),
         url.trans = url %>% as.character() %>% tolower()) %>% 
  mutate(url.new = ifelse(url.trans %in% NA,url.manual,url.trans)) %>% 
  select(participant.name.efsaweb,
         organization.name.efsaweb,
         organization.acronym.efsaweb,
         meeting.url.efsaweb,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         person.head.name,
         person.head.descr,
         person.eu.name,
         person.eu.descr,
         url.trans,
         url.manual,
         url.new,
         email.person.manual,
         title.person.manual,
         linkedin.manual) %>% 
  distinct(participant.name.efsaweb,
           organization.name.efsaweb,
           url.new,
           .keep_all = T)


efsaweb.3 %>% select(email.person.manual) %>% is.na() %>% sjmisc::frq()


#Creating short url.new
t1 <- str_split(efsaweb.3$url.new,"http://|https://", simplify = TRUE) %>% 
  data.frame() %>% 
  select(X2) 

t2<- t1$X2 %>% 
  str_split("/", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.new.short = X1)

efsaweb.3 <- efsaweb.3 %>% 
  mutate(url.new.short = t2$url.new.short) %>% 
  mutate(url.new.short.clean = url.new.short %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))

#Extracting url domains

t1 <- str_split(efsaweb.3$url.new.short,"http://|https://|www.", simplify = TRUE) %>% 
  data.frame() %>% 
  mutate(url.new.domain.t = paste0(X1,X2)) 

t2 <- str_split(t1$url.new.domain.t,"\\.", simplify = TRUE) %>% 
  data.frame() %>% 
  select(url.new.domain = X1)

efsaweb.3 <- efsaweb.3 %>% 
  mutate(url.new.domain = t2$url.new.domain) %>% 
  mutate(url.new.domain.clean = url.new.domain %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|@|http:|https:",""))
```

  

Matching email addresses with patterns of general emails 
  
```{r}  
efsaweb.emails.general.1 <- efsaweb.3 %>% 
  left_join(emails,by=c("url.new.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.new.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.new.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==T & email.domain.match==T,1,0)) %>% 
  distinct(organization.name.efsaweb,email.escraper,.keep_all = T) %>% 
  select(organization.name.efsaweb,
         organization.acronym.efsaweb,
         meeting.url.efsaweb,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         person.head.name,
         person.head.descr,
         person.eu.name,
         person.eu.descr,
         url.trans,
         url.manual,
         url.new,
         email.person.manual,
         title.person.manual,
         linkedin.manual,
         url.email.escraper,
         email.escraper,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.efsaweb,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1 <- efsaweb.emails.general.1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(email.general.str = paste(email.escraper, collapse = "; "))

t2 <- efsaweb.emails.general.1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(emails.domain.str = paste(email.escraper, collapse = "; "))

t3 <- efsaweb.emails.general.1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.efsaweb) %>% 
  summarise(emails.nondomain.str = paste(email.escraper, collapse = "; "))

t1 %>% nrow()  



efsaweb.4 <- efsaweb.3 %>% 
  left_join(t1)  %>%
  left_join(t2)  %>%
  left_join(t3)  %>%
  mutate(email.general.manual = NA) %>%
  select(-url.new.short.clean,
         -url.new.domain,
         -url.new.domain.clean) %>% 
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsaweb_emails_01.csv")


efsaweb.4 %>% select(email.person.manual) %>% is.na() %>% sjmisc::frq()

efsaweb.4 %>% 
  filter(!(email.person.manual %in% NA)|
         !(email.general.str %in% NA)) %>% 
  nrow()
```


```{r}
efsaweb.4$organization.name.efsaweb %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(email.general.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(emails.domain.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

```



##efsa stakeholders


tidy data - seperate row for each person
```{r}
efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.1 %>% 
  gather(key=trans.person.type,
             value=trans.person.name,
                c("person.head.name","person.eu.name")) %>% 
  mutate(trans.person.type = recode(trans.person.type,
                                    person.head.name="head",
                                    person.eu.name = "eu person")) %>% 
  mutate(job.descr = if_else(trans.person.type=="head",
                            person.head.descr,
                            person.eu.descr)) %>%
  mutate(trans.person.type.1 = if_else(is.na(trans.person.name==T),"missing", trans.person.type)) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type=trans.person.type.1,
         job.descr,
         organization.type.stakeholders = TYPE,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         organization.acronym.trans,
         organization.name.trans,
         organization.name.trans.clean,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,                
         organization.acronym.trans.clean,
         url.clean,
         matched.stakeholders.trans) %>%
  distinct(organization.name.stakeholders,
         trans.person.name,
         trans.person.type,
         .keep_all = T) %>% 
  arrange(organization.name.stakeholders,
          trans.person.type)

efsa.stakeholders.emails.persons.1$trans.person.name %>%
  n_distinct()
```

splitting first and last names:
```{r}
efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.emails.persons.1 %>% 

  mutate(trans.person.first.name = word(trans.person.name,1),
         trans.person.last.name = word(trans.person.name,-1)) %>% 

    mutate(trans.person.first.name.clean = trans.person.first.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""),
         trans.person.last.name.clean = trans.person.last.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/",""))
```

Creating acronyms of participant names:
```{r}
#head
t1 <- str_split(efsa.stakeholders.emails.persons.1$trans.person.name," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>% tolower())) %>% 
  mutate(trans.person.name.acronym.v1 = paste0(X1,X2,X3,X4,X5)) %>% 
  mutate(trans.person.name.acronym.v2 = paste0(str_sub(trans.person.name.acronym.v1,1,1),
                                          str_sub(trans.person.name.acronym.v1,-1,-1)))


efsa.stakeholders.emails.persons.1 <- efsa.stakeholders.emails.persons.1 %>% 
  mutate(trans.person.name.acronym.v1 = t1$trans.person.name.acronym.v1,
         trans.person.name.acronym.v2 = t1$trans.person.name.acronym.v2)

rm(t1,t2)
```

matching names:
```{r}
t1.1 <- efsa.stakeholders.emails.persons.1 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name = str_detect(email.escraper.local.part,trans.person.last.name.clean),
         email.first.name = str_detect(email.escraper.local.part,trans.person.first.name.clean),
         email.name.acronym.v1 = str_detect(email.escraper.local.part,trans.person.name.acronym.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,trans.person.name.acronym.v2)) %>% 
  mutate(email.name.match = ifelse(email.last.name==T|
                                     email.first.name==T|
                                     email.name.acronym.v1==T&nchar(email.escraper.local.part)<=4|
                                     email.name.acronym.v2==T&nchar(email.escraper.local.part)<=4,1,0)) %>%
  
  distinct(trans.person.name,
           organization.name.stakeholders,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==T) %>% 

  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type,
         job.descr,
         organization.type.stakeholders,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)
  

  
t1.2 <- efsa.stakeholders.emails.persons.1 %>% 
  anti_join(t1.1,
            by=c("trans.person.name"="trans.person.name")) %>% 
mutate(url.email.escraper = NA,
      email.escraper = NA,
      email.domain.match = NA,
      email.name.match = NA) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type,
         job.descr,
         organization.type.stakeholders,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)  


efsa.stakeholders.emails.persons.2 <- bind_rows(t1.1,t1.2) %>%

  arrange(organization.name.stakeholders,
          trans.person.type) %>%
  rename(person.email.escraper=email.escraper,
         person.url.email.escraper=url.email.escraper) 
  
  #write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders_01.csv")

t1.1$trans.person.name %>% n_distinct()
efsa.stakeholders.emails.persons.2 %>% 
  distinct(trans.person.name,.keep_all = T) %>% 
  select(trans.person.name,person.email.escraper) %>% 
  drop_na()
```


Adding general email addresses: 
 
```{r}  
t1 <- efsa.stakeholders.emails.persons.1 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.trans.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.trans.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==1 & email.domain.match==1,1,0)) %>% 
  distinct(organization.name.stakeholders,email.escraper,.keep_all = T) %>% 
  select(organization.name.stakeholders,
         acronym.stakeholders,
         trans.person.name,
         trans.person.type,
         job.descr,
         organization.type.stakeholders,
         organization.name.stakeholders.clean,
         organization.acronym.stakeholders.clean,
         id.efsa.stakeholders,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.stakeholders,
          trans.person.type,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1.1 <- t1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(email.general.str = paste(email.escraper, collapse = "; "))

t1.2 <- t1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(emails.domain.str = paste(email.escraper, collapse = "; "))

t1.3 <- t1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.stakeholders) %>% 
  summarise(emails.nondomain.str = paste(email.escraper, collapse = "; "))
  

efsa.stakeholders.emails.persons.2 <- efsa.stakeholders.emails.persons.2 %>% 
  left_join(t1.1)  %>%
  left_join(t1.2)  %>%
  left_join(t1.3)  %>%
  mutate(email.general.manual = NA) %>%
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders.emails_01.csv")

efsa.stakeholders.emails.persons.2$organization.name.stakeholders %>% n_distinct()


efsa.stakeholders.emails.persons.2 %>% select(organization.name.stakeholders,email.general.str) %>%
  distinct(organization.name.stakeholders,.keep_all = T) %>% 
  drop_na()

```


```{r}
efsaweb.4$organization.name.efsaweb %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(email.general.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(emails.domain.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

```




##transparency register


tidy data - seperate row for each person
```{r}
eu.trans.food.filter.2 <- eu.trans.food.filter %>% 
  gather(key=trans.person.type,
             value=trans.person.name,
                c("person.head.name","person.eu.name")) %>% 
  mutate(trans.person.type = recode(trans.person.type,
                                    person.head.name="head",
                                    person.eu.name = "eu person")) %>% 
  mutate(job.descr = if_else(trans.person.type=="head",
                            person.head.descr,
                            person.eu.descr)) %>%
  mutate(trans.person.type.1 = if_else(is.na(trans.person.name==T),"missing", trans.person.type)) %>% 
  
  select(trans.person.name,
         trans.person.type=trans.person.type.1,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         organization.acronym.trans,
         organization.name.trans,
         organization.name.trans.clean,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,                
         organization.acronym.trans.clean) %>%
  
distinct(organization.name.trans.raw,
         trans.person.name,
         trans.person.type,
         .keep_all = T) %>% 
  arrange(organization.name.trans.raw,
          trans.person.type)

eu.trans.food.filter.2$trans.person.name %>%
  n_distinct()
```

splitting first and last names:
```{r}
eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>% 

  mutate(trans.person.first.name = word(trans.person.name,1),
         trans.person.last.name = word(trans.person.name,-1)) %>% 

    mutate(trans.person.first.name.clean = trans.person.first.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|\\(|\\}|\\{",""),
         trans.person.last.name.clean = trans.person.last.name %>% tolower() %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|\\(|\\}|\\{",""))
```

Creating acronyms of participant names:
```{r}
#head
t1 <- str_split(eu.trans.food.filter.2$trans.person.name," |-", simplify = TRUE) %>% 
  data.frame() %>% 
mutate_all(funs(str_sub(.,1,1) %>% tolower())) %>% 
  mutate(trans.person.name.acronym.v1 = paste0(X1,X2,X3,X4,X5)) %>% 
  mutate(trans.person.name.acronym.v2 = paste0(str_sub(trans.person.name.acronym.v1,1,1),
                                          str_sub(trans.person.name.acronym.v1,-1,-1)))


eu.trans.food.filter.2 <- eu.trans.food.filter.2 %>% 
  mutate(trans.person.name.acronym.v1 = t1$trans.person.name.acronym.v1 %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|\\(|\\}|\\{",""),
         trans.person.name.acronym.v2 = t1$trans.person.name.acronym.v2 %>% str_replace_all("\n| |,|'|\\.|\\?|-|’|\\/|\\(|\\}|\\{",""))

rm(t1,t2)
```

matching names:
```{r}
t1.1 <- eu.trans.food.filter.2 %>%  
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  
  rowwise() %>% 
  mutate(email.domain.match = str_detect(trans.url.short.clean,email.escraper.domain.clean), 
         email.last.name = str_detect(email.escraper.local.part,trans.person.last.name.clean),
         email.first.name = str_detect(email.escraper.local.part,trans.person.first.name.clean)) %>%
  mutate(email.name.acronym.v1 = str_detect(email.escraper.local.part,trans.person.name.acronym.v1),
         email.name.acronym.v2 = str_detect(email.escraper.local.part,trans.person.name.acronym.v2)) %>% 
  mutate(email.name.match = ifelse(email.last.name==T|
                                     email.first.name==T|
                                     email.name.acronym.v1==T&nchar(email.escraper.local.part)<=4|
                                     email.name.acronym.v2==T&nchar(email.escraper.local.part)<=4,1,0)) %>%
  
  distinct(trans.person.name,
           organization.name.trans.raw,
           email.escraper,.keep_all = T) %>% 
  
  filter(email.name.match==T) %>% 

  select(trans.person.name,
         trans.person.type,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)
  

  
t1.2 <- eu.trans.food.filter.2 %>% 
  anti_join(t1.1,
            by=c("trans.person.name"="trans.person.name")) %>% 
mutate(url.email.escraper = NA,
      email.escraper = NA,
      email.domain.match = NA,
      email.name.match = NA) %>% 
  select(trans.person.name,
         trans.person.type,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.name.match)  


eu.trans.food.filter.3 <- bind_rows(t1.1,t1.2) %>%

  arrange(organization.name.trans.raw,
          trans.person.type) %>%
  rename(person.email.escraper=email.escraper,
         person.url.email.escraper=url.email.escraper) 
  
  #write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.stakeholders_01.csv")

t1.1$trans.person.name %>% n_distinct()
eu.trans.food.filter.3 %>% 
  distinct(trans.person.name,.keep_all = T) %>% 
  select(trans.person.name,person.email.escraper) %>% 
  drop_na()
```


Adding general email addresses: 
 
```{r}  
t1 <- eu.trans.food.filter.2 %>% 
  left_join(emails,by=c("trans.url.short.clean"="url.escraper.clean")) %>%
  rowwise() %>%
  mutate(email.domain.match.t1 = str_detect(url.trans.domain.clean,email.escraper.domain.clean) %>% as.numeric(),
         email.domain.match.t2 = str_detect(email.escraper.domain.clean, url.trans.domain.clean) %>% as.numeric()) %>% 
  mutate(email.domain.match = ifelse(email.domain.match.t1==1|email.domain.match.t2==1,1,0)) %>% 
  mutate(email.general.t = str_detect(email.escraper.local.part,email.escraper.domain)%>% as.numeric()) %>% 
  mutate(email.general = ifelse(email.general==1|email.general.t==1,1,0)) %>%
  select(-email.general.t) %>%
  mutate(email.general.domain.match = ifelse(email.general==1 & email.domain.match==1,1,0)) %>% 
  distinct(organization.name.trans.raw,email.escraper,.keep_all = T) %>% 
  select(trans.person.name,
         trans.person.type,
         job.descr,
         id.trans,
         organization.name.trans.raw,
         info.en.1,
         url,
         trans.url.short,
         trans.url.short.clean,
         url.trans.domain,
         url.trans.domain.clean,
         url.email.escraper,
         email.escraper,
         email.domain.match,
         email.general,
         email.domain.match,
         email.general.domain.match) %>% 
  arrange(organization.name.trans.raw,
          trans.person.type,
          desc(email.domain.match),
          desc(email.general.domain.match))

t1.1 <- t1 %>%
  filter(email.general.domain.match==1) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(email.general.str = paste(email.escraper, collapse = "; "))

t1.2 <- t1 %>%
  filter(email.domain.match==1,email.general==0) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(emails.domain.str = paste(email.escraper, collapse = "; "))

t1.3 <- t1 %>%
  filter(email.domain.match==0) %>% 
  group_by(organization.name.trans.raw) %>% 
  summarise(emails.nondomain.str = paste(email.escraper, collapse = "; "))
  

eu.trans.food.filter.3 <- eu.trans.food.filter.3 %>% 
  left_join(t1.1)  %>%
  left_join(t1.2)  %>%
  left_join(t1.3)  %>%
  mutate(email.general.manual = NA) %>%
  write_csv("C:/SAAR/UNIVERSITY/R/eufood/sample building/data/efsa website/efsa.trans.emails_01.csv")

eu.trans.food.filter.3$organization.name.trans.raw %>% n_distinct()


eu.trans.food.filter.3 %>% 
  select(organization.name.trans.raw,email.general.str) %>%
  distinct(organization.name.trans.raw,.keep_all = T) %>% 
  drop_na()

```


```{r}
efsaweb.4$organization.name.efsaweb %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(email.general.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

efsaweb.4 %>%
  drop_na(emails.domain.str) %>% 
  select(organization.name.efsaweb) %>% 
  n_distinct()

```


